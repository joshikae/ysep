<!DOCTYPE html>
<html>
<head>
    <title>Speech to Text</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@1.3.1/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.4.0/dist/speech-commands.min.js"></script>
</head>
<body>
    <div class="speaker" style="display: flex;justify-content: space-between;width: 13rem;box-shadow: 0 0 13px #0000003d;border-radius: 5px;">
        <p id="action" style="color: grey;font-weight: 800; padding: 0; padding-left: 2rem;"></p>
        <button onclick="runSpeechRecog()" style="border: transparent;padding: 0 0.5rem;">
            Speech
        </button>
    </div>
    <h3 id="output" class="hide"></h3>
    <div id="label-container"></div>
    <script>
        // Speech-to-Text
        runSpeechRecog = () => {
            document.getElementById("output").innerHTML = "Loading text...";
            var output = document.getElementById('output');
            var action = document.getElementById('action');
            let recognition = new webkitSpeechRecognition();
            recognition.onstart = () => {
                action.innerHTML = "Listening...";
            }
            recognition.onresult = (e) => {
                var transcript = e.results[0][0].transcript;
                output.innerHTML = transcript;
                output.classList.remove("hide")
                action.innerHTML = "";
            }
            recognition.start();
        }

        // Teachable Machine Audio Model
        const URL = "PUT_YOUR_TEACHABLE_MACHINE_AUDIO_MODEL_URL_HERE";

        async function createModel() {
            const checkpointURL = URL + "model.json"; // model topology
            const metadataURL = URL + "metadata.json"; // model metadata

            const recognizer = speechCommands.create(
                "BROWSER_FFT", // Fourier transform type, not useful to change
                undefined, // Speech commands vocabulary feature, not useful for your models
                checkpointURL,
                metadataURL
            );

            // Check that model and metadata are loaded via HTTPS requests.
            await recognizer.ensureModelLoaded();

            return recognizer;
        }

        async function init() {
            const recognizer = await createModel();
            const classLabels = recognizer.wordLabels(); // Get class labels
            const labelContainer = document.getElementById("label-container");
            for (let i = 0; i < classLabels.length; i++) {
                labelContainer.appendChild(document.createElement("div"));
            }

            // listen() takes two arguments:
            // 1. A callback function that is invoked anytime a word is recognized.
            // 2. A configuration object with adjustable fields
            recognizer.listen(
                (result) => {
                    const scores = result.scores; // Probability of prediction for each class
                    // Render the probability scores per class
                    for (let i = 0; i < classLabels.length; i++) {
                        const classPrediction = classLabels[i] + ": " + result.scores[i].toFixed(2);
                        labelContainer.childNodes[i].innerHTML = classPrediction;
                    }
                },
                {
                    includeSpectrogram: true, // In case listen should return result.spectrogram
                    probabilityThreshold: 0.75,
                    invokeCallbackOnNoiseAndUnknown: true,
                    overlapFactor: 0.50, // Probably want between 0.5 and 0.75. More info in README
                }
            );
        }

        // Initialize both functions
        window.onload = () => {
            init();
        };
    </script>
    <a href="/ysep/main.html">Text to Speech</a>
</body>
</html>

